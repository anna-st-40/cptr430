{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97121933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXERCISE 1: Agent-Environment Interaction\n",
      "======================================================================\n",
      "\n",
      "Initial state: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "Current percept: (<Location.A: 'A'>, <Status.DIRTY: 'Dirty'>)\n",
      "\n",
      "Executing actions manually:\n",
      "After SUCK: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "After RIGHT: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "After SUCK: [Clean] Agent@B [Clean] | Perf: 19\n",
      "\n",
      "Final Performance: 19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 1: Agents and Environments\n",
    "\"\"\"\n",
    "import random\n",
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "\n",
    "class Location(Enum):\n",
    "    A = \"A\"\n",
    "    B = \"B\"\n",
    "\n",
    "class Status(Enum):\n",
    "    CLEAN = \"Clean\"\n",
    "    DIRTY = \"Dirty\"\n",
    "\n",
    "class Action(Enum):\n",
    "    LEFT = \"Left\"\n",
    "    RIGHT = \"Right\"\n",
    "    SUCK = \"Suck\"\n",
    "    NOOP = \"NoOp\"\n",
    "\n",
    "class VacuumEnvironment:\n",
    "    \"\"\"Simple two-location vacuum environment\"\"\"\n",
    "    def __init__(self):\n",
    "        self.locations = {Location.A: Status.DIRTY, Location.B: Status.DIRTY}\n",
    "        self.agent_location = Location.A\n",
    "        self.performance = 0\n",
    "        self.time_steps = 0\n",
    "    \n",
    "    def percept(self) -> Tuple[Location, Status]:\n",
    "        \"\"\"Return current percept: [Location, Status]\"\"\"\n",
    "        return (self.agent_location, self.locations[self.agent_location])\n",
    "    \n",
    "    def execute(self, action: Action):\n",
    "        \"\"\"Execute action and update environment\"\"\"\n",
    "        self.time_steps += 1\n",
    "        \n",
    "        if action == Action.SUCK:\n",
    "            if self.locations[self.agent_location] == Status.DIRTY:\n",
    "                self.locations[self.agent_location] = Status.CLEAN\n",
    "                self.performance += 10  # Reward for cleaning\n",
    "        elif action == Action.LEFT:\n",
    "            self.agent_location = Location.A\n",
    "            self.performance -= 1  # Cost of movement\n",
    "        elif action == Action.RIGHT:\n",
    "            self.agent_location = Location.B\n",
    "            self.performance -= 1  # Cost of movement\n",
    "    \n",
    "    def is_clean(self) -> bool:\n",
    "        return all(status == Status.CLEAN for status in self.locations.values())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[{self.locations[Location.A].value}] Agent@{self.agent_location.value} [{self.locations[Location.B].value}] | Perf: {self.performance}\"\n",
    "\n",
    "# Demonstration\n",
    "print(\"=\"*70)\n",
    "print(\"EXERCISE 1: Agent-Environment Interaction\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "env = VacuumEnvironment()\n",
    "print(f\"\\nInitial state: {env}\")\n",
    "print(f\"Current percept: {env.percept()}\")\n",
    "print(\"\\nExecuting actions manually:\")\n",
    "\n",
    "# Manual action sequence\n",
    "env.execute(Action.SUCK)\n",
    "print(f\"After SUCK: {env}\")\n",
    "\n",
    "env.execute(Action.RIGHT)\n",
    "print(f\"After RIGHT: {env}\")\n",
    "\n",
    "env.execute(Action.SUCK)\n",
    "print(f\"After SUCK: {env}\")\n",
    "\n",
    "print(f\"\\nFinal Performance: {env.performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ba06",
   "metadata": {},
   "source": [
    "1. ## What is the difference between the agent's percept and the full environment state? Consider what information is hidden from the agent.\n",
    "    The full environment has two squares, and the squares have clean/dirty status. The percept only knows the status of the square it is currently on.\n",
    "\n",
    "\n",
    "2. ## How does the performance measure influence what actions are \"good\"? What would/could happen if we changed the reward/cost values?\n",
    "    If it cleans, it is rewarded. If it moves, it has a slight punishment. If the cost of moving was raised, especially if it was greater than the reward of cleaning, the agent might never move at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67153195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 2: Simple Reflex Agent Behavior\n",
      "======================================================================\n",
      "\n",
      "Agent Rules:\n",
      "  - IF dirty THEN suck\n",
      "  - IF at A and clean THEN move right\n",
      "  - IF at B and clean THEN move left\n",
      "\n",
      "Step 0: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Percept: (<Location.A: 'A'>, <Status.DIRTY: 'Dirty'>) → Action: Suck\n",
      "Step 1: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "  Percept: (<Location.A: 'A'>, <Status.CLEAN: 'Clean'>) → Action: Right\n",
      "Step 2: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Percept: (<Location.B: 'B'>, <Status.DIRTY: 'Dirty'>) → Action: Suck\n",
      "\n",
      "Step 3: [Clean] Agent@B [Clean] | Perf: 19\n",
      "✓ All locations clean!\n",
      "\n",
      "Final Performance Score: 19\n",
      "Steps taken: 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 2: Simple Reflex Agent (Rational Behavior)\n",
    "\"\"\"\n",
    "\n",
    "def simple_reflex_vacuum_agent(percept: Tuple[Location, Status]) -> Action:\n",
    "    \"\"\"\n",
    "    Agent function: maps current percept to action\n",
    "    Rules:\n",
    "      - If current location is dirty → SUCK\n",
    "      - If at location A and clean → move RIGHT\n",
    "      - If at location B and clean → move LEFT\n",
    "    \"\"\"\n",
    "    location, status = percept\n",
    "    \n",
    "    if status == Status.DIRTY:\n",
    "        return Action.SUCK\n",
    "    elif location == Location.A:\n",
    "        return Action.RIGHT\n",
    "    else:\n",
    "        return Action.LEFT\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 2: Simple Reflex Agent Behavior\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAgent Rules:\")\n",
    "print(\"  - IF dirty THEN suck\")\n",
    "print(\"  - IF at A and clean THEN move right\")\n",
    "print(\"  - IF at B and clean THEN move left\")\n",
    "print()\n",
    "\n",
    "env = VacuumEnvironment()\n",
    "for step in range(8):\n",
    "    percept = env.percept()\n",
    "    action = simple_reflex_vacuum_agent(percept)\n",
    "    print(f\"Step {step}: {env}\")\n",
    "    print(f\"  Percept: {percept} → Action: {action.value}\")\n",
    "    env.execute(action)\n",
    "    if env.is_clean():\n",
    "        print(f\"\\nStep {step+1}: {env}\")\n",
    "        print(\"✓ All locations clean!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nFinal Performance Score: {env.performance}\")\n",
    "print(f\"Steps taken: {env.time_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60cc34",
   "metadata": {},
   "source": [
    "1. ## In this environment, does the agent need memory to act rationally? Why or why not?\n",
    "    No. It does not need to know if the previous square was clean or dirty, it only needs to know if the current one is clean or dirty.\n",
    "\n",
    "2. ## Is this agent rational? Does it maximize expected performance given its percept sequence?\n",
    "    Yes, it is rational, because its percept sequence is to keep trying to clean both squares until they are clean.\n",
    "    \n",
    "3. ## What problem would this agent encounter in a larger environment (e.g., 10 locations)? Think about its rule structure.\n",
    "    It wouldn't know which location isn't clean until it checks all locations, expending cost of moving.\n",
    "\n",
    "4. ## Could the simple_reflex_vacuum_agent get stuck in an infinite loop? Under what circumstances?\n",
    "    Yes, if the locations kept getting dirty while the agent isn't there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd93afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXERCISE 3: Stochastic Environment\n",
      "======================================================================\n",
      "\n",
      "Environment: SUCK action has 70% success rate\n",
      "\n",
      "Step 0: [Dirty] Agent@A [Dirty] | Perf: 0\n",
      "  Action: Suck\n",
      "Step 1: [Clean] Agent@A [Dirty] | Perf: 10\n",
      "  Action: Right\n",
      "Step 2: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Action: Suck\n",
      "    ⚠ SUCK action failed!\n",
      "Step 3: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Action: Suck\n",
      "    ⚠ SUCK action failed!\n",
      "Step 4: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Action: Suck\n",
      "    ⚠ SUCK action failed!\n",
      "Step 5: [Clean] Agent@B [Dirty] | Perf: 9\n",
      "  Action: Suck\n",
      "\n",
      "✓ All locations clean!\n",
      "\n",
      "Final Performance: 19\n",
      "Total steps: 6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exercise 3: Environment Properties - Stochasticity\n",
    "\"\"\"\n",
    "\n",
    "class StochasticVacuumEnvironment(VacuumEnvironment):\n",
    "    \"\"\"Vacuum environment where SUCK action may fail\"\"\"\n",
    "    def execute(self, action: Action):\n",
    "        self.time_steps += 1\n",
    "        \n",
    "        if action == Action.SUCK:\n",
    "            if self.locations[self.agent_location] == Status.DIRTY:\n",
    "                # Only 70% success rate\n",
    "                if random.random() > 0.3:\n",
    "                    self.locations[self.agent_location] = Status.CLEAN\n",
    "                    self.performance += 10\n",
    "                else:\n",
    "                    print(\"    ⚠ SUCK action failed!\")\n",
    "        elif action == Action.LEFT:\n",
    "            self.agent_location = Location.A\n",
    "            self.performance -= 1\n",
    "        elif action == Action.RIGHT:\n",
    "            self.agent_location = Location.B\n",
    "            self.performance -= 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXERCISE 3: Stochastic Environment\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nEnvironment: SUCK action has 70% success rate\")\n",
    "print()\n",
    "\n",
    "random.seed(42)  # For reproducible results\n",
    "env_stochastic = StochasticVacuumEnvironment()\n",
    "\n",
    "for step in range(15):\n",
    "    percept = env_stochastic.percept()\n",
    "    action = simple_reflex_vacuum_agent(percept)\n",
    "    print(f\"Step {step}: {env_stochastic}\")\n",
    "    print(f\"  Action: {action.value}\")\n",
    "    env_stochastic.execute(action)\n",
    "    if env_stochastic.is_clean():\n",
    "        print(f\"\\n✓ All locations clean!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nFinal Performance: {env_stochastic.performance}\")\n",
    "print(f\"Total steps: {env_stochastic.time_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e375f43",
   "metadata": {},
   "source": [
    "1. ## Does the simple reflex agent behave rationally in the stochastic environment? Why or why not?\n",
    "    Yes. The only difference here is that the suck action sometimes fails, and the agent just keeps retrying the suck action until it works.\n",
    "2. ## What additional capability would help the agent handle stochasticity better? Think about typical failure logic.\n",
    "    \n",
    "3. ## Compare the performance scores: How much worse is performance in the stochastic environment?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cptr430 (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
